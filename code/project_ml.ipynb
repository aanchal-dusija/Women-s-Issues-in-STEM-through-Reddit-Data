{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML ANALYSIS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We need an available Java installation to run pyspark. The easiest way to do this is to install JDK and set the proper paths using conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup - Run only once per Kernel App\n",
    "%conda install openjdk -y\n",
    "\n",
    "# install PySpark\n",
    "%pip install pyspark==3.4.0\n",
    "\n",
    "# install spark-nlp\n",
    "%pip install spark-nlp==5.1.3\n",
    "\n",
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql.functions import col, lower, count, length, unix_timestamp, current_timestamp, to_date, desc\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from pyspark.sql import functions as F\n",
    "from scipy.stats import tstd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "# !pip install plotly\n",
    "# !pip install wordcloud\n",
    "import plotly.express as px\n",
    "\n",
    "# download the nltk stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import Window\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, IDF, HashingTF, StopWordsRemover\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType, MapType, StringType\n",
    "import string\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, StopWordsCleaner, LemmatizerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creating a Spark session with increased memory allocation\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PySparkApp\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "    .config(\n",
    "        \"fs.s3a.aws.credentials.provider\",\n",
    "        \"com.amazonaws.auth.ContainerCredentialsProvider\",\n",
    "    )\n",
    "    .config(\"spark.executor.memory\", \"8g\")  \n",
    "    .config(\"spark.driver.memory\", \"8g\")  \n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Printing the version of Apache Spark\n",
    "print(\"Using Apache Spark Version\", spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "!wget -qO- https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/jars/spark-nlp-assembly-5.1.3.jar | aws s3 cp - s3://{bucket}/lab8/spark-nlp-assembly-5.1.3.jar\n",
    "!aws s3 ls s3://{bucket}/lab8/spark-nlp-assembly-5.1.3.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the filtered data\n",
    "\n",
    "Now that we have filtered the data to only keep submissions and comments from subreddits of interest. Let us read data from the s3 path where we saved the filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls s3://sagemaker-us-east-1-572044129183/project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_bucket = 'sagemaker-us-east-1-572044129183'\n",
    "output_prefix = 'project/comments/'\n",
    "s3_input_path_comments = f\"s3a://{public_bucket}/{output_prefix}\"\n",
    "comments = spark.read.parquet(s3_input_path_comments)\n",
    "print(f\"shape of the comments dataframe is {comments.count():,}x{len(comments.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check counts (ensuring all needed subreddits exist)\n",
    "comments.groupBy('subreddit').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display a subset of columns\n",
    "comments.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"link_id\", \"id\", \"created_utc\", \"score\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_bucket = 'sagemaker-us-east-1-572044129183'\n",
    "output_prefix = 'project/submissions/'\n",
    "s3_input_path_submissions = f\"s3a://{public_bucket}/{output_prefix}\"\n",
    "submissions = spark.read.parquet(s3_input_path_submissions)\n",
    "print(f\"shape of the submissions dataframe is {submissions.count():,}x{len(submissions.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check counts (ensuring all needed subreddits exist)\n",
    "submissions.groupBy('subreddit').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display a subset of columns\n",
    "submissions.select(\"subreddit\", \"author\", \"title\", \"selftext\", \"created_utc\", \"num_comments\", \"score\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter \"AskWomen\", \"AskFeminists\", \"Feminism\" by STEM Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Subreddits to filter by keywords\n",
    "keyword_subreddits = [\"AskWomen\", \"AskFeminists\", \"Feminism\"]\n",
    "# Subreddits to include all comments from\n",
    "include_all_subreddits = [\"xxstem\", \"LadiesofScience\", \"womenEngineers\"]\n",
    "\n",
    "# Define keywords for case-insensitive search\n",
    "keywords = [\"STEM\", \"Science\", \"Technology\", \"Engineering\", \"Mathematics\", \"Process\", \"Design\", \"Model\", \"Plan\", \"Project\"]\n",
    "keywords_lower = [kw.lower() for kw in keywords]\n",
    "\n",
    "# Filter the DataFrame\n",
    "comments = comments.filter(\n",
    "    (col(\"subreddit\").isin(keyword_subreddits) & col(\"body\").rlike('|'.join(keywords_lower))) |\n",
    "    (col(\"subreddit\").isin(include_all_subreddits))\n",
    ")\n",
    "\n",
    "# Show the filtered data\n",
    "comments.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"link_id\", \"id\", \"created_utc\", \"score\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Subreddits to filter by keywords\n",
    "keyword_subreddits = [\"AskWomen\", \"AskFeminists\", \"Feminism\"]\n",
    "# Subreddits to include all submissions from\n",
    "include_all_subreddits = [\"xxstem\", \"LadiesofScience\", \"womenEngineers\"]\n",
    "\n",
    "# Define keywords for case-insensitive search\n",
    "keywords = [\"STEM\", \"science\", \"technology\", \"engineering\", \"mathematics\", \"process\", \"design\", \"model\", \"plan\", \"project\"]\n",
    "# Create a regex pattern to match any keyword (case-insensitive)\n",
    "pattern = '|'.join([f\"(?i){kw}\" for kw in keywords])\n",
    "\n",
    "# Filter the DataFrame\n",
    "# Include all submissions from certain subreddits or those that match the keyword pattern in their title or selftext\n",
    "submissions = submissions.filter(\n",
    "    (col(\"subreddit\").isin(keyword_subreddits) & (col(\"title\").rlike(pattern) | col(\"selftext\").rlike(pattern))) |\n",
    "    col(\"subreddit\").isin(include_all_subreddits)\n",
    ")\n",
    "\n",
    "# Show the filtered data\n",
    "submissions.select(\"subreddit\", \"author\", \"title\", \"selftext\", \"created_utc\", \"num_comments\", \"score\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove rows with missing values in 'author' and 'body'\n",
    "comments = comments.filter(col(\"author\").isNotNull() & col(\"body\").isNotNull())\n",
    "\n",
    "# Assume that 'created_utc' should be a timestamp within the last 3 years\n",
    "three_years_ago = unix_timestamp(current_timestamp()) - (3 * 365 * 24 * 60 * 60)\n",
    "comments = comments.filter(\n",
    "    unix_timestamp(col(\"created_utc\")) > three_years_ago\n",
    ")\n",
    "\n",
    "# Show the filtered data\n",
    "comments.select(\"subreddit\", \"author\", \"body\", \"parent_id\", \"link_id\", \"id\", \"created_utc\", \"score\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove rows with missing values in 'author' or 'title'\n",
    "submissions = submissions.filter(col(\"author\").isNotNull() & col(\"title\").isNotNull())\n",
    "\n",
    "# Assume that 'created_utc' should be a timestamp within the last 3 years\n",
    "three_years_ago = unix_timestamp(current_timestamp()) - (3 * 365 * 24 * 60 * 60)\n",
    "submissions = submissions.filter(\n",
    "    unix_timestamp(col(\"created_utc\")) > three_years_ago\n",
    ")\n",
    "\n",
    "# Show the filtered data\n",
    "submissions.select(\"subreddit\", \"author\", \"title\", \"selftext\", \"created_utc\", \"num_comments\",  \"score\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.sql.functions import udf, col, explode, array_union\n",
    "from pyspark.sql.types import StringType\n",
    "import re\n",
    "\n",
    "# Define a UDF for cleaning text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "clean_text_udf = udf(clean_text, StringType())\n",
    "\n",
    "# Preprocess and tokenize text for both datasets\n",
    "comments = comments.withColumn(\"cleaned_body\", clean_text_udf(\"body\"))\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"cleaned_body\", outputCol=\"words\")\n",
    "comments = tokenizer.transform(comments)\n",
    "\n",
    "# Additional stop words\n",
    "additional_stop_words = [\"like\", \"dont\", \"im\", \"one\", \"removed\", \"get\", \"also\", \"even\", \"really\", \"sa\", \"despite\", \"certainly\"]\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "remover.setStopWords(remover.getStopWords() + additional_stop_words)\n",
    "comments = remover.transform(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions = submissions.withColumn(\"cleaned_title\", clean_text_udf(\"title\"))\n",
    "submissions = submissions.withColumn(\"cleaned_selftext\", clean_text_udf(\"selftext\"))\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"cleaned_title\", outputCol=\"title_words\")\n",
    "submissions = tokenizer.transform(submissions)\n",
    "tokenizer = Tokenizer(inputCol=\"cleaned_selftext\", outputCol=\"selftext_words\")\n",
    "submissions = tokenizer.transform(submissions)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"title_words\", outputCol=\"filtered_title_words\")\n",
    "remover.setStopWords(remover.getStopWords() + additional_stop_words)\n",
    "submissions = remover.transform(submissions)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"selftext_words\", outputCol=\"filtered_selftext_words\")\n",
    "remover.setStopWords(remover.getStopWords() + additional_stop_words)\n",
    "submissions = remover.transform(submissions)\n",
    "\n",
    "# Combine title and selftext words for submissions\n",
    "submissions = submissions.withColumn(\"combined_words\", array_union(\"filtered_title_words\", \"filtered_selftext_words\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the score of a submissions based on the text of the submissions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Split the comments dataset\n",
    "train_comments, test_comments = comments.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "# Split the submissions dataset\n",
    "train_submissions, test_submissions = submissions.randomSplit([0.7, 0.3], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "cv_submissions = CountVectorizer(inputCol=\"combined_words\", outputCol=\"features\")\n",
    "idf_submissions = IDF(inputCol=\"features\", outputCol=\"final_features\")\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"final_features\", labelCol=\"score\")\n",
    "pipeline_lr = Pipeline(stages=[cv_submissions, idf_submissions, lr])\n",
    "model_lr = pipeline_lr.fit(train_submissions)\n",
    "predictions_lr = model_lr.transform(test_submissions)\n",
    "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse_lr = evaluator.evaluate(predictions_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"final_features\", labelCol=\"score\")\n",
    "pipeline_rf = Pipeline(stages=[cv_submissions, idf_submissions, rf])\n",
    "model_rf = pipeline_rf.fit(train_submissions)\n",
    "predictions_rf = model_rf.transform(test_submissions)\n",
    "rmse_rf = evaluator.evaluate(predictions_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gradient Boosted Trees (GBTRegressor)\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "gbt = GBTRegressor(featuresCol=\"final_features\", labelCol=\"score\", maxIter=10)\n",
    "pipeline_gbt = Pipeline(stages=[cv_submissions, idf_submissions, gbt])\n",
    "model_gbt = pipeline_gbt.fit(train_submissions)\n",
    "predictions_gbt = model_gbt.transform(test_submissions)\n",
    "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse_gbt = evaluator.evaluate(predictions_gbt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol=\"final_features\", labelCol=\"score\")\n",
    "pipeline_dt = Pipeline(stages=[cv_submissions, idf_submissions, dt])\n",
    "model_dt = pipeline_dt.fit(train_submissions)\n",
    "predictions_dt = model_dt.transform(test_submissions)\n",
    "rmse_dt = evaluator.evaluate(predictions_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RMSE Scores\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for Linear Regression = %g\" % rmse_lr)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for Random Forest Regressor = %g\" % rmse_rf)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for GBTRegressor = %g\" % rmse_gbt)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data for DecisionTreeRegressor = %g\" % rmse_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# R-square Scores\n",
    "\n",
    "r2_lr = evaluator.evaluate(predictions_lr, {evaluator.metricName: \"r2\"})\n",
    "print(\"R2 on test data for Linear Regression = %g\" % r2_lr)\n",
    "\n",
    "r2_rf = evaluator.evaluate(predictions_rf, {evaluator.metricName: \"r2\"})\n",
    "print(\"R2 on test data for Random Forest Regressor = %g\" % r2_rf)\n",
    "\n",
    "r2_gbt = evaluator.evaluate(predictions_gbt, {evaluator.metricName: \"r2\"})\n",
    "print(\"R2 on test data for GBTRegressor = %g\" % r2_gbt)\n",
    "\n",
    "r2_dt = evaluator.evaluate(predictions_dt, {evaluator.metricName: \"r2\"})\n",
    "print(\"R2 on test data for Decision Tree Regressor = %g\" % r2_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "data = [\n",
    "    [\"Linear Regression\", rmse_lr, r2_lr],\n",
    "    [\"Random Forest Regressor\", rmse_rf, r2_rf],\n",
    "    [\"GBTRegressor\", rmse_gbt, r2_gbt],\n",
    "    [\"DecisionTreeRegressor\", rmse_dt, r2_dt]\n",
    "]\n",
    "\n",
    "headers = [\"Model Name\", \"RMSE\", \"R-squared\"]\n",
    "table = tabulate(data, headers, tablefmt=\"grid\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "models = [\"Linear Regression\", \"Random Forest Regressor\", \"GBTRegressor\", \"DecisionTreeRegressor\"]\n",
    "rmse_values = [rmse_lr, rmse_rf, rmse_gbt, rmse_dt]\n",
    "r2_values = [r2_lr, r2_rf, r2_gbt, r2_dt]\n",
    "\n",
    "trace_rmse = go.Bar(x=models, y=rmse_values, name=\"RMSE\")\n",
    "trace_r2 = go.Bar(x=models, y=r2_values, name=\"R-squared\")\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(trace_rmse)\n",
    "fig.add_trace(trace_r2)\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            buttons=list([\n",
    "                dict(\n",
    "                    args=[\"visible\", [True, False]],\n",
    "                    label=\"RMSE\",\n",
    "                    method=\"restyle\"\n",
    "                ),\n",
    "                dict(\n",
    "                    args=[\"visible\", [False, True]],\n",
    "                    label=\"R-squared\",\n",
    "                    method=\"restyle\"\n",
    "                )\n",
    "            ]),\n",
    "            direction=\"down\",\n",
    "            showactive=True,\n",
    "        ),\n",
    "    ],\n",
    "    title=\"Model Performance Comparison\",\n",
    ")\n",
    "\n",
    "fig.data[0].visible = True\n",
    "fig.data[1].visible = False\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we predict which subreddit a submission came from based on the text of the submission?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "subreddits_list = [\"AskWomen\", \"Feminism\", \"LadiesofScience\", \"womenEngineers\", \"AskFeminists\"]  \n",
    "filtered_submissions = submissions.filter(col(\"subreddit\").isin(subreddits_list))\n",
    "sampled_submissions = filtered_submissions.sampleBy(\"subreddit\", \n",
    "                                                    fractions={subreddit: 350/filtered_submissions.filter(col(\"subreddit\") == subreddit).count() \n",
    "                                                               for subreddit in subreddits_list}, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Define a UDF to assign labels to each subreddit\n",
    "def label_subreddit(subreddit):\n",
    "    return subreddits_list.index(subreddit)\n",
    "\n",
    "label_subreddit_udf = udf(label_subreddit, IntegerType())\n",
    "\n",
    "# Create a new column with labels\n",
    "sampled_submissions = sampled_submissions.withColumn(\"label\", label_subreddit_udf(col(\"subreddit\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws\n",
    "\n",
    "combined_text = sampled_submissions.withColumn(\"text\", concat_ws(\" \", col(\"title\").cast(\"string\"), col(\"selftext\").cast(\"string\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"text_tokens\", pattern=\"\\\\W\")\n",
    "tokenized_data = tokenizer.transform(combined_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, test_data = tokenized_data.randomSplit([0.8, 0.2], seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"text_tokens\", outputCol=\"features\")\n",
    "cv_model = cv.fit(train_data)\n",
    "train_data = cv_model.transform(train_data)\n",
    "test_data = cv_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", family=\"multinomial\")\n",
    "lr_model = lr.fit(train_data)\n",
    "predictions_lr = lr_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "rf_model = rf.fit(train_data)\n",
    "predictions_rf = rf_model.transform(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
    "nb_model = nb.fit(train_data)\n",
    "predictions_nb = nb_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "dt_model = dt.fit(train_data)\n",
    "predictions_dt = dt_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "predictions_pd_rf = predictions_rf.select(\"prediction\", \"label\").toPandas()\n",
    "predictions_pd_dt = predictions_dt.select(\"prediction\", \"label\").toPandas()\n",
    "predictions_pd_lr = predictions_lr.select(\"prediction\", \"label\").toPandas()\n",
    "predictions_pd_nb = predictions_nb.select(\"prediction\", \"label\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix_rf = confusion_matrix(predictions_pd_rf['label'], predictions_pd_rf['prediction'])\n",
    "conf_matrix_dt = confusion_matrix(predictions_pd_dt['label'], predictions_pd_dt['prediction'])\n",
    "conf_matrix_lr = confusion_matrix(predictions_pd_lr['label'], predictions_pd_lr['prediction'])\n",
    "conf_matrix_nb = confusion_matrix(predictions_pd_nb['label'], predictions_pd_nb['prediction'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "def add_confusion_matrix_trace(cm, model_name, visible=False):\n",
    "    trace = go.Heatmap(\n",
    "        z=cm,\n",
    "        x=['AskWomen 0', 'Feminism 1', 'LadiesofScience 2', 'womenEngineers 3', 'AskFeminists 4'],\n",
    "        y=['AskWomen 0', 'Feminism 1', 'LadiesofScience 2', 'womenEngineers 3', 'AskFeminists 4'],\n",
    "        colorscale='Viridis',\n",
    "        showscale=False,\n",
    "        visible=visible\n",
    "    )\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "    for i, row in enumerate(cm):\n",
    "        for j, value in enumerate(row):\n",
    "            fig.add_annotation(dict(\n",
    "                font=dict(color=\"white\"),\n",
    "                x=j,\n",
    "                y=i,\n",
    "                showarrow=False,\n",
    "                text=str(value),\n",
    "                xref=\"x\",\n",
    "                yref=\"y\",\n",
    "                visible=visible\n",
    "            ))\n",
    "\n",
    "add_confusion_matrix_trace(conf_matrix_rf, \"Random Forest\", visible=True)\n",
    "add_confusion_matrix_trace(conf_matrix_dt, \"Decision Tree\")\n",
    "add_confusion_matrix_trace(conf_matrix_lr, \"Logistic Regression\")\n",
    "add_confusion_matrix_trace(conf_matrix_nb, \"Naive Bayes\")\n",
    "\n",
    "buttons = [\n",
    "    dict(label=\"Random Forest\",\n",
    "         method=\"update\",\n",
    "         args=[{\"visible\": [True, False, False, False]},\n",
    "               {\"title\": \"Confusion Matrix for Random Forest\"}]),\n",
    "    dict(label=\"Decision Tree\",\n",
    "         method=\"update\",\n",
    "         args=[{\"visible\": [False, True, False, False]},\n",
    "               {\"title\": \"Confusion Matrix for Decision Tree\"}]),\n",
    "    dict(label=\"Logistic Regression\",\n",
    "         method=\"update\",\n",
    "         args=[{\"visible\": [False, False, True, False]},\n",
    "               {\"title\": \"Confusion Matrix for Logistic Regression\"}]),\n",
    "    dict(label=\"Naive Bayes\",\n",
    "         method=\"update\",\n",
    "         args=[{\"visible\": [False, False, False, True]},\n",
    "               {\"title\": \"Confusion Matrix for Naive Bayes\"}]),\n",
    "]\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            active=0,\n",
    "            buttons=buttons,\n",
    "            direction=\"down\",\n",
    "            pad={\"r\": 5, \"t\": 5},\n",
    "            showactive=True,\n",
    "            x=1.2,\n",
    "            xanchor=\"left\",\n",
    "            y=1.15,\n",
    "            yanchor=\"top\"\n",
    "        ),\n",
    "    ],\n",
    "    title_text=\"Confusion Matrix for Random Forest\",\n",
    "    xaxis=dict(title='Predicted label'),\n",
    "    yaxis=dict(title='True label')\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "file_path = 'CF.html'  \n",
    "fig.write_html(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "n_classes = 5\n",
    "y_test = label_binarize(predictions_pd_lr['label'], classes=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predictions_pd_lr['probability'].apply(lambda x: x[i]))\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example mapping\n",
    "class_to_subreddit = {\n",
    "    0: \"AskWomen\",\n",
    "    1: \"Feminism\",\n",
    "    2: \"LadiesofScience\",\n",
    "    3: \"womenEngineers\",\n",
    "    4: \"AskFeminists\"\n",
    "}\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from itertools import cycle\n",
    "\n",
    "fig = go.Figure()\n",
    "colors = cycle(['blue', 'red', 'green', 'yellow', 'purple'])\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    subreddit_name = class_to_subreddit[i]  # Get the subreddit name using the mapping\n",
    "    fig.add_trace(go.Scatter(x=fpr[i], y=tpr[i], mode='lines', name=f'{subreddit_name} AUC = {roc_auc[i]:.2f}', line=dict(color=color)))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROC Curve by Subreddit',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "    xaxis=dict(constrain='domain'),\n",
    "    width=800,  \n",
    "    height=600  \n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "file_path = 'ROC_Curve_By_Subreddit.html'  \n",
    "fig.write_html(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "def calculate_metrics(predictions):\n",
    "    precision = precision_evaluator.evaluate(predictions)\n",
    "    recall = recall_evaluator.evaluate(predictions)\n",
    "    f1 = f1_evaluator.evaluate(predictions)\n",
    "    accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "precision_lr, recall_lr, f1_lr, accuracy_lr = calculate_metrics(predictions_lr)\n",
    "precision_rf, recall_rf, f1_rf, accuracy_rf = calculate_metrics(predictions_rf)\n",
    "precision_nb, recall_nb, f1_nb, accuracy_nb = calculate_metrics(predictions_nb)\n",
    "precision_dt, recall_dt, f1_dt, accuracy_dt = calculate_metrics(predictions_dt)\n",
    "\n",
    "print(\"Logistic Regression - Precision:\", precision_lr, \"Recall:\", recall_lr, \"F1 Score:\", f1_lr, \"Accuracy:\", accuracy_lr)\n",
    "print(\"Random Forest - Precision:\", precision_rf, \"Recall:\", recall_rf, \"F1 Score:\", f1_rf, \"Accuracy:\", accuracy_rf)\n",
    "print(\"Naive Bayes - Precision:\", precision_nb, \"Recall:\", recall_nb, \"F1 Score:\", f1_nb, \"Accuracy:\", accuracy_nb)\n",
    "print(\"Decision Tree - Precision:\", precision_dt, \"Recall:\", recall_dt, \"F1 Score:\", f1_dt, \"Accuracy:\", accuracy_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import numpy as np\n",
    "\n",
    "def calculate_auc_per_class(predictions, num_classes, probability_col, label_col):\n",
    "    \"\"\"\n",
    "    Calculate the AUROC per class for a multiclass classification problem.\n",
    "    \"\"\"\n",
    "    auroc_per_class = []\n",
    "\n",
    "    # Convert dataframe to RDD\n",
    "    for class_index in range(num_classes):\n",
    "        # Prepare the data - convert to binary problem\n",
    "        binary_prediction = predictions.select(probability_col, label_col).rdd.map(lambda row: (float(row[probability_col][class_index]), 1.0 if row[label_col] == class_index else 0.0))\n",
    "\n",
    "        # Compute the metric for this binary problem\n",
    "        metrics = BinaryClassificationMetrics(binary_prediction)\n",
    "        auroc = metrics.areaUnderROC\n",
    "        auroc_per_class.append(auroc)\n",
    "\n",
    "    return auroc_per_class\n",
    "\n",
    "# Calculate AUROC for each class in Logistic Regression model\n",
    "num_classes = len(subreddits_list)\n",
    "auroc_per_class_lr = calculate_auc_per_class(predictions_lr, num_classes, \"probability\", \"label\")\n",
    "\n",
    "# Calculate the average AUROC\n",
    "average_auroc_lr = np.mean(auroc_per_class_lr)\n",
    "average_auroc_lr, auroc_per_class_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auroc_per_class_rf = calculate_auc_per_class(predictions_rf, num_classes, \"probability\", \"label\")\n",
    "average_auroc_rf = np.mean(auroc_per_class_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auroc_per_class_nb = calculate_auc_per_class(predictions_nb, num_classes, \"probability\", \"label\")\n",
    "average_auroc_nb = np.mean(auroc_per_class_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auroc_per_class_dt = calculate_auc_per_class(predictions_dt, num_classes, \"probability\", \"label\")\n",
    "average_auroc_dt = np.mean(auroc_per_class_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_auroc_rf, auroc_per_class_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_auroc_nb, auroc_per_class_nb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_auroc_dt, auroc_per_class_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_class_roc(predictions, num_classes, probability_col, label_col, num_thresholds=100):\n",
    "    roc_auc_dict = {}\n",
    "\n",
    "    for class_index in range(num_classes):\n",
    "        binary_prediction = predictions.select(probability_col, label_col).rdd.map(\n",
    "            lambda row: (float(row[probability_col][class_index]), 1.0 if row[label_col] == class_index else 0.0)\n",
    "        )\n",
    "        scores_and_labels = binary_prediction.collect()\n",
    "\n",
    "        # Use a common set of thresholds\n",
    "        thresholds = np.linspace(0, 1, num_thresholds)\n",
    "        roc_points = []\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            tp = fp = tn = fn = 0\n",
    "            for score, label in scores_and_labels:\n",
    "                if score >= threshold:\n",
    "                    if label == 1.0:\n",
    "                        tp += 1\n",
    "                    else:\n",
    "                        fp += 1\n",
    "                else:\n",
    "                    if label == 1.0:\n",
    "                        fn += 1\n",
    "                    else:\n",
    "                        tn += 1\n",
    "\n",
    "            fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "            tpr = tp / (tp + fn) if (tp + fn) else 0\n",
    "            roc_points.append((fpr, tpr))\n",
    "\n",
    "        # Calculate AUC\n",
    "        fpr, tpr = zip(*roc_points)\n",
    "        roc_auc = np.trapz(tpr, fpr)\n",
    "\n",
    "        roc_auc_dict[class_index] = (fpr, tpr, roc_auc)\n",
    "\n",
    "    return roc_auc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "roc_auc_lr = calculate_class_roc(predictions_lr, num_classes, \"probability\", \"label\")\n",
    "\n",
    "# Repeat for other models\n",
    "roc_auc_rf = calculate_class_roc(predictions_rf, num_classes, \"probability\", \"label\")\n",
    "roc_auc_nb = calculate_class_roc(predictions_nb, num_classes, \"probability\", \"label\")\n",
    "roc_auc_dt = calculate_class_roc(predictions_dt, num_classes, \"probability\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_roc_data(roc_auc_dict, num_thresholds=100):\n",
    "    # Initialize lists for aggregated TPR and FPR\n",
    "    aggregated_fpr = np.linspace(0, 1, num_thresholds)\n",
    "    aggregated_tpr = []\n",
    "\n",
    "    for threshold in aggregated_fpr:\n",
    "        tpr_list = []\n",
    "\n",
    "        for _, (fpr, tpr, _) in roc_auc_dict.items():\n",
    "            # Find closest FPR point and get corresponding TPR\n",
    "            closest_fpr_index = np.argmin(np.abs(np.array(fpr) - threshold))\n",
    "            tpr_list.append(tpr[closest_fpr_index])\n",
    "\n",
    "        # Average TPR across all classes for this threshold\n",
    "        aggregated_tpr.append(np.mean(tpr_list))\n",
    "\n",
    "    # Calculate AUC\n",
    "    aggregated_auc = np.trapz(aggregated_tpr, aggregated_fpr)\n",
    "\n",
    "    return aggregated_fpr, aggregated_tpr, aggregated_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate ROC data for each model\n",
    "aggregated_roc_lr = aggregate_roc_data(roc_auc_lr)\n",
    "aggregated_roc_rf = aggregate_roc_data(roc_auc_rf)\n",
    "aggregated_roc_nb = aggregate_roc_data(roc_auc_nb)\n",
    "aggregated_roc_dt = aggregate_roc_data(roc_auc_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "# Create traces for each model\n",
    "trace_lr = go.Scatter(x=aggregated_roc_lr[0], y=aggregated_roc_lr[1],\n",
    "                      mode='lines', name=f'Logistic Regression (AUC = {aggregated_roc_lr[2]:.2f})')\n",
    "trace_rf = go.Scatter(x=aggregated_roc_rf[0], y=aggregated_roc_rf[1],\n",
    "                      mode='lines', name=f'Random Forest (AUC = {aggregated_roc_rf[2]:.2f})')\n",
    "trace_nb = go.Scatter(x=aggregated_roc_nb[0], y=aggregated_roc_nb[1],\n",
    "                      mode='lines', name=f'Naive Bayes (AUC = {aggregated_roc_nb[2]:.2f})')\n",
    "trace_dt = go.Scatter(x=aggregated_roc_dt[0], y=aggregated_roc_dt[1],\n",
    "                      mode='lines', name=f'Decision Tree (AUC = {aggregated_roc_dt[2]:.2f})')\n",
    "\n",
    "# Define layout\n",
    "layout = go.Layout(\n",
    "    title='Aggregated Receiver Operating Characteristic',\n",
    "    xaxis=dict(title='False Positive Rate'),\n",
    "    yaxis=dict(title='True Positive Rate'),\n",
    "    legend=dict(x=1.1, y=0.9),\n",
    "    margin=dict(l=40, r=40, b=40, t=40)\n",
    ")\n",
    "\n",
    "# Create figure and add traces\n",
    "fig = go.Figure(data=[trace_lr, trace_rf, trace_nb, trace_dt], layout=layout)\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n",
    "\n",
    "file_path = 'ROC.html'  \n",
    "fig.write_html(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: FIND COMMON THEMES OR SIMILARITIES IN  COMMENTS ACROSS DIFFERENT SUBREDDITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install scikit-learn nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments = comments.filter(col(\"subreddit\") == \"xxstem\")\n",
    "comments.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means CLustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Convert tokens to TF-IDF features\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# KMeans Clustering\n",
    "num_clusters = 3  # Set the number of clusters\n",
    "kmeans = KMeans(featuresCol=\"features\", k=num_clusters, seed=123)\n",
    "\n",
    "# Create a pipeline and fit it\n",
    "pipeline = Pipeline(stages=[cv, idf, kmeans])\n",
    "model = pipeline.fit(comments)\n",
    "\n",
    "# Predict clusters\n",
    "predictions = model.transform(comments)\n",
    "\n",
    "# Evaluating the clustering\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"prediction\", metricName=\"silhouette\")\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"Silhouette with squared euclidean distance = {silhouette}\")\n",
    "\n",
    "# Show the results\n",
    "predictions.select(\"filtered_words\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to convert Spark DataFrame vector column to a NumPy array\n",
    "def vector_to_array(v):\n",
    "    return np.array(v.toArray()).tolist()\n",
    "\n",
    "features_array = np.array(predictions.select('features').rdd.map(lambda row: vector_to_array(row.features)).collect())\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(features_array)\n",
    "\n",
    "# Creating a DataFrame for Plotly\n",
    "plotly_df = pd.DataFrame(pca_result, columns=['PCA1', 'PCA2'])\n",
    "plotly_df['Cluster'] = np.array(predictions.select('prediction').rdd.map(lambda row: row.prediction).collect())\n",
    "\n",
    "# Color mapping for clusters\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, color in enumerate(colors[:num_clusters]):\n",
    "    cluster_df = plotly_df[plotly_df['Cluster'] == i]\n",
    "    fig.add_trace(go.Scatter(x=cluster_df['PCA1'], y=cluster_df['PCA2'], \n",
    "                             mode='markers', \n",
    "                             name=f'Cluster {i}',\n",
    "                             marker_color=color))\n",
    "\n",
    "fig.update_layout(title='PCA of K-Means Clustering',\n",
    "                  xaxis_title='PCA Component 1',\n",
    "                  yaxis_title='PCA Component 2',\n",
    "                  legend_title='Cluster')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "fig.write_html(\"pca.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierachial Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# Function to convert vector to array\n",
    "def vector_to_array(v):\n",
    "    return v.toArray().tolist()\n",
    "\n",
    "# UDF for converting vector to array\n",
    "vector_to_array_udf = udf(vector_to_array, ArrayType(DoubleType()))\n",
    "\n",
    "features_df = predictions.withColumn(\"features_array\", vector_to_array_udf(\"features\"))\n",
    "features_list = features_df.select(\"features_array\").rdd.map(lambda x: x[0]).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Convert to numpy array\n",
    "features_np = np.array(features_list)\n",
    "\n",
    "# Hierarchical Clustering\n",
    "linked = linkage(features_np, 'ward')\n",
    "\n",
    "# Creating the dendrogram\n",
    "fig = ff.create_dendrogram(linked, orientation='left')\n",
    "fig.update_layout(width=800, height=800)\n",
    "fig.show()\n",
    "\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=num_clusters, affinity='euclidean', linkage='ward')\n",
    "labels = agg_clustering.fit_predict(features_np)\n",
    "\n",
    "# Calculating Silhouette Score\n",
    "silhouette_avg = silhouette_score(features_np, labels)\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: The work has been by us. However, we have taken assissstance from ChatGPT for code commenting and cleaning."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
